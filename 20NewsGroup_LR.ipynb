{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedHamood/20NewsGroup/blob/main/20NewsGroup_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nGPW7BV152e"
      },
      "source": [
        "# 20NewsGroup - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1UHEjaVFgwM"
      },
      "source": [
        "MEMO: Include any decisions about training/validation split, regularization\n",
        "strategies, any optimization tricks, setting hyper-parameters, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e89IS-aq2AKz"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YATSwO2luyBW",
        "outputId": "ce1e026d-8255-4f99-d99a-027e422ef103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import pipelines_FEngineering as BaseLine\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import preprocessingNLP as PNLP\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.decomposition import PCA, NMF,TruncatedSVD\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Import Dataset\n",
        "TNGD_Train = fetch_20newsgroups(subset='train',shuffle=True, random_state=42,remove=['headers', 'footers', 'quotes'])\n",
        "TNGD_test = fetch_20newsgroups(subset='test',shuffle=True, random_state=42,remove=['headers', 'footers', 'quotes'])\n",
        "\n",
        "# Preprocessing\n",
        "print(\"PREPROCESSING ...\")\n",
        "TNGD_Train.data = PNLP.customNLP(TNGD_Train.data)\n",
        "TNGD_test.data = PNLP.customNLP(TNGD_test.data)\n",
        "TNGD_Train.data, TNGD_Train.target = PNLP.removeEmptyInstances(TNGD_Train.data, TNGD_Train.target)\n",
        "\n",
        "\n",
        "\n",
        "print(\"PREPROCESSING DONE!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "PREPROCESSING ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PREPROCESSING DONE!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6wa9jeg1-PD"
      },
      "source": [
        "## Cross-Validation Splitting Strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4JezyHUGiRr"
      },
      "source": [
        "Let's first analyse how the cross-validation splitting strategy makes an impact on the training accuracy of the dataset using Logistic Regression classifier with its default parameters. In the following experiment, Logistic Regression will be applied on the dataset for different number of folds (5 to 15). The elapsed time will also be collected for each training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvFH3wDJ2HV0"
      },
      "source": [
        "# Logistic Regression Model\n",
        "accuracies = []\n",
        "folds = []\n",
        "runtimes = []\n",
        "for i in range(5,16):\n",
        "  start = time.perf_counter()\n",
        "  LR_base = BaseLine.Pipeline_FeatureEngineering(TNGD_Train.data, TNGD_Train.target,\n",
        "                                                parameters={}, CV=i,\n",
        "                                                reductionMethod=TruncatedSVD(n_components=100),\n",
        "                                                reductionType=3, model=LogisticRegression(n_jobs=-1))\n",
        "  end = time.perf_counter()\n",
        "  elapsed_time = end-start\n",
        "  accuracies.append(LR_base.best_score_)\n",
        "  folds.append(i)\n",
        "  runtimes.append(elapsed_time)\n",
        "\n",
        "#Display Results\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax1.plot(folds, accuracies, 'o-')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_xlabel('Fold Size')\n",
        "ax2.plot(folds, runtimes, 'o-')\n",
        "ax2.set_ylabel('Training Time')\n",
        "ax2.set_xlabel('Fold Size')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7MPHe58FZ8T"
      },
      "source": [
        "The first graph shows that within a range of 5 to 15 folds, a 11-fold cross-validation gives the best accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxrwHBflzAmx"
      },
      "source": [
        "## Setting Hyper-Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5daffjcqy33O"
      },
      "source": [
        "In the following section, RandomSearchCV is used to evaluate the validation accuracy of Logistic Regression based on random combinations of hyper-parameters used in the validation pipeline. The relevant parameters needed for CountVectorizer are max_features and ngram_range whereas the parameters for TfidfTransformer are use_idf and norm. Logistic Regression is used with its default values except for max_itr=400, which guarantees convergence on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8snS6B2OJNuF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "# Set possible parameters\n",
        "parameters = {\n",
        "     'vect__max_features': (None, 50000, 100000),\n",
        "     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
        "     'tfidf__use_idf': (True, False),\n",
        "     'tfidf__norm': ('l1', 'l2'),\n",
        "}\n",
        "\n",
        "# Create a pipeline\n",
        "pip = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
        "                ('Norm', Normalizer(copy=False)),('clf', LogisticRegression(max_iter=400, n_jobs=-1))])\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "n_iter_search = 10\n",
        "cv_folds = 11\n",
        "LR_rand_search = RandomizedSearchCV(pip, param_distributions=parameters, \n",
        "                               n_iter=n_iter_search, cv=cv_folds)\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=10):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
        "                  .format(results['mean_test_score'][candidate],\n",
        "                          results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "# Execute RandomizedSearchCV and print best results\n",
        "LR_rand_search.fit(TNGD_Train.data, TNGD_Train.target)\n",
        "report(LR_rand_search.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVHWRAql8Uno"
      },
      "source": [
        "These results show a brief idea of the required parameters for CountVectorizer and TfidfTransformer.\n",
        "RandomSearchCV constantly gives different rankings as it always chooses its parameters randomly. However, to improve the probabilities of obtaining the best accuracy, the parameters used for rank 1 are applied for the next experiments. \n",
        "\n",
        "Now, RandomizedSearchCV is used to evaluate the hyper-parameters that could potentially optimize the validation accuracy of Logistic Regression. Only the relevant parameters of the model are evaluated. The 'saga' solver, a Stochastic Average Gradient variant, is used for optimization because it is compatible with the different L1 and L2 regularizations and it also converges faster on large datasets. A Normalizer is also included in the pipeline to make sure that the features have the same scale which guarantees fast convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2THj0rFt8Y4x"
      },
      "source": [
        "# Get parameters used for rank 1\n",
        "indices = np.flatnonzero(LR_rand_search.cv_results_['rank_test_score'] == 1)\n",
        "rank1_params = LR_rand_search.cv_results_['params'][indices[0]]\n",
        "ngram_range = rank1_params['vect__ngram_range']\n",
        "max_features = rank1_params['vect__max_features']\n",
        "\n",
        "\n",
        "# Set relevant parameters\n",
        "parameters = {\n",
        "     'clf__penalty': ('l2', 'l1'),\n",
        "     'clf__max_iter': (300, 400, 500),\n",
        "     'clf__C': (0.5, 1.0, 10.0),\n",
        "     'clf__tol': (0.001, 0.0001)\n",
        "}\n",
        "\n",
        "# Create a pipeline\n",
        "pip = Pipeline([('vect', CountVectorizer(ngram_range=ngram_range, max_features=max_features)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('Norm', Normalizer(copy=False)),('clf', LogisticRegression(solver='saga', n_jobs=-1))])\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "n_iter_search=10\n",
        "cv_folds=10\n",
        "LR_rand_search2 = RandomizedSearchCV(pip, param_distributions=parameters, \n",
        "                               n_iter=n_iter_search, cv=cv_folds)\n",
        "\n",
        "# Execute RandomizedSearchCV and print best results \n",
        "LR_rand_search2.fit(TNGD_Train.data, TNGD_Train.target)\n",
        "report(LR_rand_search2.cv_results_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DTXaN_O9gZO"
      },
      "source": [
        "In the following section, GridSearchCV is used to properly detect the most optimal parameters needed to optimize the validation accuracy of Logistic Regression. \n",
        "\n",
        "The previous results help to properly select the hyper-parameters. It seems that the default tolerance of 0.0001 is a good value for stochastic gradient descent. It also seems that a higher validation accuracy is obtained when no penalty is applied on the training. Although this might look good, it could also be a sign of overfitting, which could then generate a poor test accuracy. To avoid this issue, Lasso Regression (L1 penalty) is applied with an appropriate regularization strength. Indeed, this type of regression works the best because it produces sparse weights, which helps with feature selection by reducing the amount of features in the provided design matrix. This eventually reduces the complexity of the model. Furthermore, every test was able to find the minimum error without reaching the maximum iteration provided in the paremeters. Therefore, 300 iterations seems like an appropriate maximum value. Finally, using GridSearchCV helps choosing the appropriate regularization strength for the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVoOE82B_a_"
      },
      "source": [
        "# Set relevant parameters\n",
        "parameters = {\n",
        "    'clf__C': (0.1, 1.0, 10)\n",
        "}\n",
        "\n",
        "# Create a pipeline\n",
        "pip = Pipeline([('vect', CountVectorizer(ngram_range=ngram_range, max_features=max_features)),\n",
        "                ('tfidf', TfidfTransformer(use_idf=use_idf)),\n",
        "                ('Norm', Normalizer(copy=False)),\n",
        "                ('clf', LogisticRegression(max_iter=300, penalty='l1', solver='saga', n_jobs=-1))])\n",
        "\n",
        "# Initialize and execute GridSearchCV\n",
        "gs_clf = GridSearchCV(pip, parameters, cv=cv_folds, n_jobs=-1)\n",
        "start_time = time.perf_counter()\n",
        "gs_clf = gs_clf.fit(IMDB_train.data, IMDB_train.target)\n",
        "elapsed_time = time.perf_counter() - start_time\n",
        "\n",
        "# Print results\n",
        "print(\"Validation Accuracy: \" + str(gs_clf.best_score_))\n",
        "print(\"Optimal Parameters: \" + str(gs_clf.best_estimator_))\n",
        "print(\"Optimal Parameters: \" + str(gs_clf.best_params_))\n",
        "print(\"\")\n",
        "\n",
        "train_accuracies = gs_clf.cv_results_['mean_test_score']\n",
        "train_time = gs_clf.cv_results_['mean_fit_time']\n",
        "train_params = gs_clf.cv_results_['params']\n",
        "\n",
        "for i in range(len(train_time)):\n",
        "  print(\"Parameter: {0}\".format(train_params[i]))\n",
        "  print(\"Training Time: %.3f seconds\" %train_time[i])\n",
        "  print(\"Valdation Accuracy: {0:.3f}\".format(train_accuracies[i]))\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}